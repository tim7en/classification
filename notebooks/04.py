{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Landcover Classification Analysis for Uzbekistan\n",
    "This notebook processes the comprehensive satellite tiles downloaded from Google Earth Engine and performs landcover classification using the training labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.features import geometry_mask\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Paths and Load Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "project_root = Path.cwd().parent\n",
    "data_dir = project_root / \"data\"\n",
    "training_dir = data_dir / \"training\"\n",
    "tiles_dir = data_dir / \"downloaded_tiles\"  # You'll need to copy tiles from Google Drive here\n",
    "results_dir = data_dir / \"results\"\n",
    "models_dir = data_dir / \"models\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "tiles_dir.mkdir(parents=True, exist_ok=True)\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÇ Project root: {project_root}\")\n",
    "print(f\"üìÇ Training data: {training_dir}\")\n",
    "print(f\"üìÇ Tiles directory: {tiles_dir}\")\n",
    "print(f\"üìÇ Results directory: {results_dir}\")\n",
    "\n",
    "# Define the 12 landcover classes from your training data\n",
    "LANDCOVER_CLASSES = {\n",
    "    1: 'Residential',\n",
    "    2: 'Agriculture', \n",
    "    3: 'Buildings',\n",
    "    4: 'Forest',\n",
    "    5: 'Residential_Private',\n",
    "    6: 'Roads_Highways',\n",
    "    7: 'Land_Stock',\n",
    "    8: 'Non_Residential',\n",
    "    9: 'Protected',\n",
    "    10: 'Railways',\n",
    "    11: 'Shared_Lands',\n",
    "    12: 'Water'\n",
    "}\n",
    "\n",
    "print(\"\\nüéØ Landcover Classes:\")\n",
    "for class_id, class_name in LANDCOVER_CLASSES.items():\n",
    "    print(f\"   {class_id:2d}. {class_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Training Labels from GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training GeoJSON file\n",
    "training_geojson = training_dir / \"landcover_training.geojson\"\n",
    "\n",
    "if training_geojson.exists():\n",
    "    print(f\"üìÇ Loading training data: {training_geojson}\")\n",
    "    training_gdf = gpd.read_file(training_geojson)\n",
    "    \n",
    "    # Ensure CRS is set (assuming WGS84 if not specified)\n",
    "    if training_gdf.crs is None:\n",
    "        training_gdf.set_crs('EPSG:4326', inplace=True)\n",
    "    \n",
    "    print(f\"‚úÖ Training data loaded successfully!\")\n",
    "    print(f\"   üìä Total features: {len(training_gdf):,}\")\n",
    "    print(f\"   üóÇÔ∏è  Columns: {list(training_gdf.columns)}\")\n",
    "    print(f\"   üåç CRS: {training_gdf.crs}\")\n",
    "    \n",
    "    # Analyze class distribution\n",
    "    if 'layer_id' in training_gdf.columns:\n",
    "        layer_counts = training_gdf['layer_id'].value_counts().sort_index()\n",
    "        print(f\"\\nüìà Training Data Distribution:\")\n",
    "        for layer_id, count in layer_counts.items():\n",
    "            if layer_id in LANDCOVER_CLASSES:\n",
    "                print(f\"   {layer_id:2d}. {LANDCOVER_CLASSES[layer_id]:18}: {count:6,} polygons\")\n",
    "else:\n",
    "    print(f\"‚ùå Training data not found: {training_geojson}\")\n",
    "    print(\"Please ensure landcover_training.geojson is in the training directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load and Explore Satellite Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for available tiles\n",
    "print(\"üîç Checking for downloaded tiles...\")\n",
    "print(\"\\nüì• Please copy your downloaded GeoTIFF files from Google Drive to:\")\n",
    "print(f\"   {tiles_dir}\")\n",
    "print(\"\\nExpected files:\")\n",
    "print(\"   - uzbekistan_tile_recent_3_months_comprehensive.tif\")\n",
    "print(\"   - uzbekistan_tile_summer_2023_comprehensive.tif\")\n",
    "print(\"   - uzbekistan_tile_winter_2023_2024_comprehensive.tif\")\n",
    "\n",
    "# List available TIF files\n",
    "tif_files = list(tiles_dir.glob(\"*.tif\")) + list(tiles_dir.glob(\"*.tiff\"))\n",
    "if tif_files:\n",
    "    print(f\"\\n‚úÖ Found {len(tif_files)} tile(s):\")\n",
    "    for tif_file in tif_files:\n",
    "        print(f\"   - {tif_file.name}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No TIF files found in the tiles directory.\")\n",
    "    print(\"   Please download and copy the tiles from Google Drive first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_explore_tile(tile_path):\n",
    "    \"\"\"Load a satellite tile and display its properties\"\"\"\n",
    "    with rasterio.open(tile_path) as src:\n",
    "        print(f\"\\nüìä Tile Information: {tile_path.name}\")\n",
    "        print(f\"   - Shape: {src.height} x {src.width} pixels\")\n",
    "        print(f\"   - Bands: {src.count}\")\n",
    "        print(f\"   - CRS: {src.crs}\")\n",
    "        print(f\"   - Pixel Size: {src.res[0]}m x {src.res[1]}m\")\n",
    "        print(f\"   - Bounds: {src.bounds}\")\n",
    "        \n",
    "        # List band names based on our comprehensive export\n",
    "        band_names = [\n",
    "            'SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7',\n",
    "            'NDVI', 'NDWI', 'MNDWI', 'NDBI', 'EVI', 'SAVI',\n",
    "            'elevation', 'SLOPE', 'ASPECT', 'HILLSHADE',\n",
    "            'TERRAIN_MOUNTAIN', 'WATER_MASK',\n",
    "            'VEG_SPARSE', 'VEG_MODERATE', 'VEG_DENSE',\n",
    "            'TEMP_C', 'NIR_TEXTURE'\n",
    "        ]\n",
    "        \n",
    "        print(\"\\n   üìä Band Information:\")\n",
    "        for i, name in enumerate(band_names[:src.count], 1):\n",
    "            print(f\"      Band {i:2d}: {name}\")\n",
    "        \n",
    "        return src.meta, band_names[:src.count]\n",
    "\n",
    "# Load and explore the first available tile\n",
    "if tif_files:\n",
    "    tile_meta, band_names = load_and_explore_tile(tif_files[0])\n",
    "    selected_tile = tif_files[0]\n",
    "    print(f\"\\n‚úÖ Selected tile for analysis: {selected_tile.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Extract Training Samples from Satellite Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pixel_values(raster_path, polygons_gdf, class_column='layer_id'):\n",
    "    \"\"\"\n",
    "    Extract pixel values from raster for each polygon in the GeoDataFrame.\n",
    "    Returns features (X) and labels (y) for training.\n",
    "    \"\"\"\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # Ensure CRS match\n",
    "        if polygons_gdf.crs != src.crs:\n",
    "            print(f\"üîÑ Reprojecting polygons from {polygons_gdf.crs} to {src.crs}\")\n",
    "            polygons_gdf = polygons_gdf.to_crs(src.crs)\n",
    "        \n",
    "        # Read all bands\n",
    "        raster_data = src.read()\n",
    "        \n",
    "        print(f\"üìä Extracting pixels from {len(polygons_gdf)} polygons...\")\n",
    "        \n",
    "        for idx, row in polygons_gdf.iterrows():\n",
    "            if idx % 1000 == 0:\n",
    "                print(f\"   Processing polygon {idx}/{len(polygons_gdf)}...\")\n",
    "            \n",
    "            try:\n",
    "                # Get the geometry and class label\n",
    "                geom = row.geometry\n",
    "                class_id = row[class_column]\n",
    "                \n",
    "                # Skip if invalid class\n",
    "                if class_id not in LANDCOVER_CLASSES:\n",
    "                    continue\n",
    "                \n",
    "                # Create mask for this polygon\n",
    "                mask_transform = src.transform\n",
    "                polygon_mask = geometry_mask(\n",
    "                    [geom],\n",
    "                    transform=mask_transform,\n",
    "                    invert=True,\n",
    "                    out_shape=(src.height, src.width)\n",
    "                )\n",
    "                \n",
    "                # Extract pixels within the polygon\n",
    "                masked_data = raster_data[:, polygon_mask]\n",
    "                \n",
    "                if masked_data.shape[1] > 0:\n",
    "                    # Transpose to get pixels as rows, bands as columns\n",
    "                    pixels = masked_data.T\n",
    "                    \n",
    "                    # Add to lists\n",
    "                    features_list.append(pixels)\n",
    "                    labels_list.extend([class_id] * pixels.shape[0])\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è  Error processing polygon {idx}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Combine all features\n",
    "    if features_list:\n",
    "        X = np.vstack(features_list)\n",
    "        y = np.array(labels_list)\n",
    "        print(f\"\\n‚úÖ Extracted {X.shape[0]:,} pixels with {X.shape[1]} features each\")\n",
    "        return X, y\n",
    "    else:\n",
    "        print(\"‚ùå No features extracted\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract training samples if we have both tiles and training data\n",
    "if tif_files and 'training_gdf' in locals():\n",
    "    print(\"üöÄ Starting feature extraction...\")\n",
    "    X, y = extract_pixel_values(selected_tile, training_gdf)\n",
    "    \n",
    "    if X is not None:\n",
    "        # Remove any pixels with NaN or infinite values\n",
    "        valid_pixels = ~np.any(np.isnan(X) | np.isinf(X), axis=1)\n",
    "        X = X[valid_pixels]\n",
    "        y = y[valid_pixels]\n",
    "        \n",
    "        print(f\"\\nüìä Final dataset:\")\n",
    "        print(f\"   - Features shape: {X.shape}\")\n",
    "        print(f\"   - Labels shape: {y.shape}\")\n",
    "        print(f\"   - Unique classes: {np.unique(y)}\")\n",
    "        \n",
    "        # Show class distribution\n",
    "        print(\"\\nüìà Class distribution in extracted pixels:\")\n",
    "        for class_id in np.unique(y):\n",
    "            count = np.sum(y == class_id)\n",
    "            percentage = (count / len(y)) * 100\n",
    "            print(f\"   {class_id:2d}. {LANDCOVER_CLASSES[class_id]:18}: {count:8,} pixels ({percentage:5.2f}%)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Missing tiles or training data. Please ensure both are available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Train Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X' in locals() and X is not None:\n",
    "    # Split data into training and testing sets\n",
    "    print(\"üîÑ Splitting data into train/test sets...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"   Training set: {X_train.shape[0]:,} pixels\")\n",
    "    print(f\"   Test set: {X_test.shape[0]:,} pixels\")\n",
    "    \n",
    "    # Train Random Forest classifier\n",
    "    print(\"\\nüå≤ Training Random Forest Classifier...\")\n",
    "    rf_classifier = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=20,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    print(\"‚úÖ Model training complete!\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nüìä Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Save the model\n",
    "    model_path = models_dir / \"rf_landcover_classifier.joblib\"\n",
    "    joblib.dump(rf_classifier, model_path)\n",
    "    print(f\"\\nüíæ Model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'rf_classifier' in locals():\n",
    "    # Generate classification report\n",
    "    print(\"\\nüìä Classification Report:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create label names for the report\n",
    "    class_names = [LANDCOVER_CLASSES[i] for i in sorted(np.unique(y_test))]\n",
    "    \n",
    "    report = classification_report(\n",
    "        y_test, y_pred,\n",
    "        target_names=class_names,\n",
    "        digits=3\n",
    "    )\n",
    "    print(report)\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = rf_classifier.feature_importances_\n",
    "    \n",
    "    # Create feature importance dataframe\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': band_names,\n",
    "        'importance': feature_importance\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nüéØ Top 10 Most Important Features:\")\n",
    "    print(\"=\"*40)\n",
    "    for idx, row in importance_df.head(10).iterrows():\n",
    "        print(f\"{row['feature']:20} : {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "if 'rf_classifier' in locals():\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(\n",
    "        cm, \n",
    "        annot=True, \n",
    "        fmt='d', \n",
    "        cmap='Blues',\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names\n",
    "    )\n",
    "    plt.title('Confusion Matrix - Landcover Classification', fontsize=16)\n",
    "    plt.xlabel('Predicted Class', fontsize=12)\n",
    "    plt.ylabel('True Class', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(results_dir / 'confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nüíæ Confusion matrix saved to: {results_dir / 'confusion_matrix.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Apply Model to Create Landcover Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_raster(raster_path, model, output_path, chunk_size=1000):\n",
    "    \"\"\"\n",
    "    Apply the trained model to classify the entire raster.\n",
    "    Process in chunks to manage memory.\n",
    "    \"\"\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # Get metadata for output\n",
    "        meta = src.meta.copy()\n",
    "        meta.update({\n",
    "            'dtype': 'uint8',\n",
    "            'count': 1,\n",
    "            'compress': 'lzw'\n",
    "        })\n",
    "        \n",
    "        # Create output raster\n",
    "        with rasterio.open(output_path, 'w', **meta) as dst:\n",
    "            # Process in chunks\n",
    "            for i in range(0, src.height, chunk_size):\n",
    "                # Calculate chunk boundaries\n",
    "                row_start = i\n",
    "                row_end = min(i + chunk_size, src.height)\n",
    "                \n",
    "                print(f\"Processing rows {row_start} to {row_end} of {src.height}...\")\n",
    "                \n",
    "                # Read chunk\n",
    "                window = rasterio.windows.Window(\n",
    "                    0, row_start, \n",
    "                    src.width, row_end - row_start\n",
    "                )\n",
    "                chunk_data = src.read(window=window)\n",
    "                \n",
    "                # Reshape for prediction (pixels x bands)\n",
    "                n_bands, n_rows, n_cols = chunk_data.shape\n",
    "                chunk_reshaped = chunk_data.transpose(1, 2, 0).reshape(-1, n_bands)\n",
    "                \n",
    "                # Handle NaN and infinite values\n",
    "                valid_pixels = ~np.any(np.isnan(chunk_reshaped) | np.isinf(chunk_reshaped), axis=1)\n",
    "                predictions = np.zeros(chunk_reshaped.shape[0], dtype=np.uint8)\n",
    "                \n",
    "                if np.any(valid_pixels):\n",
    "                    # Predict only on valid pixels\n",
    "                    predictions[valid_pixels] = model.predict(chunk_reshaped[valid_pixels])\n",
    "                \n",
    "                # Reshape back and write\n",
    "                predictions_2d = predictions.reshape(n_rows, n_cols)\n",
    "                dst.write(predictions_2d, 1, window=window)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Classification complete! Output saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the model to create a landcover map\n",
    "if 'rf_classifier' in locals() and tif_files:\n",
    "    print(\"üó∫Ô∏è  Creating landcover classification map...\")\n",
    "    \n",
    "    # Define output path\n",
    "    output_map = results_dir / f\"landcover_map_{selected_tile.stem}.tif\"\n",
    "    \n",
    "    # Classify the raster\n",
    "    classify_raster(selected_tile, rf_classifier, output_map)\n",
    "    \n",
    "    print(f\"\\nüéâ Landcover map created successfully!\")\n",
    "    print(f\"   üìç Location: {output_map}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Model or tiles not available for classification.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a sample of the classification result\n",
    "if (results_dir / f\"landcover_map_{selected_tile.stem}.tif\").exists():\n",
    "    with rasterio.open(results_dir / f\"landcover_map_{selected_tile.stem}.tif\") as src:\n",
    "        # Read a sample area (center of the image)\n",
    "        h, w = src.height, src.width\n",
    "        sample_size = min(2000, h, w)\n",
    "        \n",
    "        window = rasterio.windows.Window(\n",
    "            (w - sample_size) // 2,\n",
    "            (h - sample_size) // 2,\n",
    "            sample_size,\n",
    "            sample_size\n",
    "        )\n",
    "        \n",
    "        sample_data = src.read(1, window=window)\n",
    "        \n",
    "        # Create color map\n",
    "        from matplotlib.colors import ListedColormap\n",
    "        colors = [\n",
    "            '#FF6B6B',  # Residential\n",
    "            '#4ECDC4',  # Agriculture\n",
    "            '#45B7D1',  # Buildings\n",
    "            '#96CEB4',  # Forest\n",
    "            '#FFEAA7',  # Residential_Private\n",
    "            '#DDA0DD',  # Roads_Highways\n",
    "            '#98D8C8',  # Land_Stock\n",
    "            '#F7DC6F',  # Non_Residential\n",
    "            '#85C1E2',  # Protected\n",
    "            '#F8B739',  # Railways\n",
    "            '#52BE80',  # Shared_Lands\n",
    "            '#3498DB'   # Water\n",
    "        ]\n",
    "        \n",
    "        cmap = ListedColormap(colors[:len(LANDCOVER_CLASSES)])\n",
    "        \n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        im = ax.imshow(sample_data, cmap=cmap, vmin=1, vmax=len(LANDCOVER_CLASSES))\n",
    "        ax.set_title('Landcover Classification Sample (Center Region)', fontsize=16)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Add colorbar with class labels\n",
    "        cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar.set_ticks(list(LANDCOVER_CLASSES.keys()))\n",
    "        cbar.set_ticklabels(list(LANDCOVER_CLASSES.values()))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(results_dir / 'landcover_sample_visualization.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nüíæ Visualization saved to: {results_dir / 'landcover_sample_visualization.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üéâ LANDCOVER CLASSIFICATION ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if 'rf_classifier' in locals():\n",
    "    print(f\"\\nüìä Model Performance:\")\n",
    "    print(f\"   ‚Ä¢ Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Number of training pixels: {X_train.shape[0]:,}\")\n",
    "    print(f\"   ‚Ä¢ Number of features: {X_train.shape[1]}\")\n",
    "    print(f\"   ‚Ä¢ Number of classes: {len(LANDCOVER_CLASSES)}\")\n",
    "\n",
    "print(f\"\\nüìÅ Output Files:\")\n",
    "if (models_dir / \"rf_landcover_classifier.joblib\").exists():\n",
    "    print(f\"   ‚úÖ Model: {models_dir / 'rf_landcover_classifier.joblib'}\")\n",
    "if (results_dir / f\"landcover_map_{selected_tile.stem}.tif\").exists():\n",
    "    print(f\"   ‚úÖ Landcover Map: {results_dir / f'landcover_map_{selected_tile.stem}.tif'}\")\n",
    "if (results_dir / 'confusion_matrix.png').exists():\n",
    "    print(f\"   ‚úÖ Confusion Matrix: {results_dir / 'confusion_matrix.png'}\")\n",
    "if (results_dir / 'landcover_sample_visualization.png').exists():\n",
    "    print(f\"   ‚úÖ Sample Visualization: {results_dir / 'landcover_sample_visualization.png'}\")\n",
    "\n",
    "print(f\"\\nüöÄ Next Steps:\")\n",
    "print(\"   1. Review the confusion matrix to identify classes that need improvement\")\n",
    "print(\"   2. Analyze feature importance to understand which bands are most useful\")\n",
    "print(\"   3. Consider adding more training data for underrepresented classes\")\n",
    "print(\"   4. Apply the model to other seasonal tiles for temporal analysis\")\n",
    "print(\"   5. Export results to GIS software for further analysis\")\n",
    "print(\"   6. Consider ensemble methods or deep learning for improved accuracy\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}